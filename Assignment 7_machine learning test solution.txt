In Q1 to Q7, only one option is correct, Choose the correct option:

1. The value of correlation coefficient will always be:
C) between -1 and 1

2. Which of the following cannot be used for dimensionality reduction?
D) Ridge Regularisation

3. Which of the following is not a kernel in Support Vector Machines?

C) hyperplane

4. Amongst the following, which one is least suitable for a dataset having non-linear decision boundaries?

D) Support Vector Classifier

5. In a Linear Regression problem, ‘X’ is independent variable and ‘Y’ is dependent variable, where ‘X’ represents weight in pounds. If you convert the unit of ‘X’ to kilograms, then new coefficient of ‘X’ will be?

A) 2.205 × old coefficient of ‘X’

6. As we increase the number of estimators in ADABOOST Classifier, what happens to the accuracy of the model?

B) increases

7. Which of the following is not an advantage of using random forest instead of decision trees?

 C) Random Forests are easy to interpret

In Q8 to Q10, more than one options are correct, Choose all the correct options:

8. Which of the following are correct about Principal Components?

Ans. B) Principal Components are calculated using unsupervised learning techniques
     C) Principal Components are linear combinations of Linear Variables. 


9. Which of the following are applications of clustering?

Ans B) Identifying loan defaulters in a bank on the basis of previous years’ data of loan accounts.
    C) Identifying spam or ham emails

10. Which of the following is(are) hyper parameters of a decision tree?

Ans: A) max_depth
     B) max_features
     D) min_samples_leaf

Q11 to Q15 are subjective answer type questions, Answer them briefly.

11. What are outliers? Explain the Inter Quartile Range(IQR) method for outlier detection.

Ans) An outlier is a data point that differs significantly from other observations. An outlier may be due to variability in the measurement or it may indicate experimental error.
     The latter are sometimes excluded from the data set.An outlier can cause serious problems in statistical analyses.

    Inter Quartile Range(IQR) method for outlier detection:
	*Calculate the interquartile range for the data (IQR = Q3 - Q1).
	*Multiply the interquartile range (IQR) by 1.5 (IQR*1.5).
 	*Subtract 1.5 x (IQR) from the first quartile (Lower Bound: (Q1 - 1.5 * IQR)). Any number less than this is treated as outlier.
 	*Add 1.5 x (IQR) to the third quartile (Upper Bound: (Q3 + 1.5 * IQR)). Any number greater than this is treated as outlier.
	* if a data point is below Q1 – 1.5×IQR or above Q3 + 1.5×IQR, it is viewed as being too far from the central values to be reasonable

12. What is the primary difference between bagging and boosting algorithms?

Ans): Bagging and Boosting are both ensemble methods in Machine Learning.
	
	Bagging:
	*Different training data subsets are randomly drawn with replacement from the entire training dataset.
	*Bagging tries to solve over-fitting problem.
	*If the classifier is unstable (high variance), then apply bagging.
	*Each model receives equal weight.
	*Aim to decrease variance, not bias.
	
	Boosting Alg:
	*Every new subsets contains the elements that were misclassified by previous models.
	*Boosting tries to reduce bias.
	*If the classifier is stable and simple (high bias) the apply boosting.
	*Models are weighted according to their performance.
	*Aim to decrease bias, not variance.

13. What is adjusted R2 in logistic regression. How is it calculated?

Ans): Adjusted R2 denotes the corresponding value but for the null model - the model with only an intercept and no covariates.
		R2 = 1 – [ln LL(Mˆfull)]/[ln LL(Mˆintercept)]
	
14. What is the difference between standardisation and normalisation?
Ans): Normalization:
	*Usually means to scale a variable to have a values between 0 and 1
	*is good to use when you know that the distribution of your data does not follow a Gaussian distribution. 
	*This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks.
      
	standardization:
	*while standardization transforms data to have a mean of zero and a standard deviation of 1.
	*on the other hand, can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range.
	* So, even if you have outliers in your data, they will not be affected by standardization.

15. What is cross-validation? Describe one advantage and one disadvantage of using cross-validation?
Ans): Cross-validation is a technique in which we train our model using the subset of the data-set and then evaluate using the complementary subset of the data-set.
	*Advantage: It prevents our model from overfitting the training dataset.
	*Disadvantage: Cross Validation drastically increases the training time.

