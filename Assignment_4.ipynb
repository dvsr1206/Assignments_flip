{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
    "from keras import backend as k\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded completely\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "filename='Assignment_3.zip'\n",
    "with ZipFile(filename,'r') as file:\n",
    "    file.extractall()\n",
    "    print('loaded completely')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               34669056  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 34,763,843\n",
      "Trainable params: 34,763,843\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# SGD with Momentum\n",
    "\n",
    "model11=Sequential()\n",
    "model11.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model11.add(MaxPooling2D(2,2))\n",
    "model11.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model11.add(MaxPooling2D(2,2))\n",
    "model11.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model11.add(MaxPooling2D(2,2))\n",
    "\n",
    "model11.add(Flatten())\n",
    "\n",
    "model11.add(Dense(512, activation='relu'))\n",
    "model11.add(Dropout(0.25))\n",
    "model11.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model11.compile(SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/train',\n",
    "                                              target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical',\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1=callbacks.ModelCheckpoint('m1cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=4,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.002, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 351s 3s/step - loss: 0.7628 - accuracy: 0.6208 - val_loss: 0.4650 - val_accuracy: 0.8998\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46504, saving model to m1cp.h5\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 331s 3s/step - loss: 0.3335 - accuracy: 0.8672 - val_loss: 0.4309 - val_accuracy: 0.8834\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.46504 to 0.43090, saving model to m1cp.h5\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 332s 3s/step - loss: 0.1902 - accuracy: 0.9286 - val_loss: 0.0784 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.43090 to 0.07838, saving model to m1cp.h5\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 325s 3s/step - loss: 0.0955 - accuracy: 0.9667 - val_loss: 0.5474 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07838\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 329s 3s/step - loss: 0.0808 - accuracy: 0.9651 - val_loss: 0.4035 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07838\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999552965164e-05.\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 328s 3s/step - loss: 0.1245 - accuracy: 0.9495 - val_loss: 0.0061 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07838 to 0.00607, saving model to m1cp.h5\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 330s 3s/step - loss: 0.1044 - accuracy: 0.9620 - val_loss: 0.0677 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00607\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 329s 3s/step - loss: 0.0821 - accuracy: 0.9714 - val_loss: 0.0205 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00607\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.9999998989515006e-08.\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 331s 3s/step - loss: 0.0725 - accuracy: 0.9724 - val_loss: 0.1645 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00607\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 332s 3s/step - loss: 0.0735 - accuracy: 0.9729 - val_loss: 0.0138 - val_accuracy: 0.9498\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00607\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 7.999999951380232e-11.\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1=model11.fit_generator(train_set,\n",
    "                             steps_per_epoch=1926//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1,cb1,ro1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 21, 21, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 3,518,659\n",
      "Trainable params: 3,518,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "model1.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "model1.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "model1.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1.add(MaxPooling2D(2,2))\n",
    "model1.add(Dropout(0.4))\n",
    "\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1.compile(SGD(learning_rate=0.001, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set1a1 = train_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=32,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set1a1 = test_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=32,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1a=callbacks.ModelCheckpoint('m1acp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1a= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=4,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1a=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.002, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60/60 [==============================] - 422s 7s/step - loss: 1.0879 - accuracy: 0.3906 - val_loss: 1.0664 - val_accuracy: 0.3667\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.06640, saving model to m1acp.h5\n",
      "Epoch 2/20\n",
      "60/60 [==============================] - 409s 7s/step - loss: 1.0539 - accuracy: 0.4917 - val_loss: 0.9551 - val_accuracy: 0.7167\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.06640 to 0.95514, saving model to m1acp.h5\n",
      "Epoch 3/20\n",
      "60/60 [==============================] - 414s 7s/step - loss: 0.9755 - accuracy: 0.5484 - val_loss: 0.7211 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.95514 to 0.72115, saving model to m1acp.h5\n",
      "Epoch 4/20\n",
      "60/60 [==============================] - 412s 7s/step - loss: 0.8155 - accuracy: 0.6234 - val_loss: 0.6589 - val_accuracy: 0.6833\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.72115 to 0.65894, saving model to m1acp.h5\n",
      "Epoch 5/20\n",
      "60/60 [==============================] - 412s 7s/step - loss: 0.6871 - accuracy: 0.6870 - val_loss: 0.5470 - val_accuracy: 0.7333\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65894 to 0.54705, saving model to m1acp.h5\n",
      "Epoch 6/20\n",
      "60/60 [==============================] - 415s 7s/step - loss: 0.5924 - accuracy: 0.7339 - val_loss: 0.4239 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54705 to 0.42388, saving model to m1acp.h5\n",
      "Epoch 7/20\n",
      "60/60 [==============================] - 426s 7s/step - loss: 0.5136 - accuracy: 0.7714 - val_loss: 0.3296 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.42388 to 0.32955, saving model to m1acp.h5\n",
      "Epoch 8/20\n",
      "60/60 [==============================] - 408s 7s/step - loss: 0.4393 - accuracy: 0.8125 - val_loss: 0.2691 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.32955 to 0.26912, saving model to m1acp.h5\n",
      "Epoch 9/20\n",
      "60/60 [==============================] - 405s 7s/step - loss: 0.3935 - accuracy: 0.8302 - val_loss: 0.5243 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.26912\n",
      "Epoch 10/20\n",
      "60/60 [==============================] - 401s 7s/step - loss: 0.3446 - accuracy: 0.8651 - val_loss: 0.2104 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.26912 to 0.21035, saving model to m1acp.h5\n",
      "Epoch 11/20\n",
      "60/60 [==============================] - 398s 7s/step - loss: 0.3000 - accuracy: 0.8740 - val_loss: 0.1241 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.21035 to 0.12407, saving model to m1acp.h5\n",
      "Epoch 12/20\n",
      "60/60 [==============================] - 406s 7s/step - loss: 0.2658 - accuracy: 0.8953 - val_loss: 0.2523 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12407\n",
      "Epoch 13/20\n",
      "60/60 [==============================] - 398s 7s/step - loss: 0.2739 - accuracy: 0.8865 - val_loss: 0.2548 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.12407\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.0000000949949025e-06.\n",
      "Epoch 14/20\n",
      "60/60 [==============================] - 398s 7s/step - loss: 0.6199 - accuracy: 0.7750 - val_loss: 0.4438 - val_accuracy: 0.8167\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.12407\n",
      "Epoch 15/20\n",
      "60/60 [==============================] - 391s 7s/step - loss: 0.5799 - accuracy: 0.7833 - val_loss: 0.4823 - val_accuracy: 0.8333\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12407\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.999999989900971e-09.\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1a=model1.fit_generator(train_set1a1,\n",
    "                             steps_per_epoch=1920//32,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1a1,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1a,cb1a,ro1a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1b=Sequential()\n",
    "model1b.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1b.add(MaxPooling2D(2,2))\n",
    "model1b.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1b.add(MaxPooling2D(2,2))\n",
    "model1b.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1b.add(MaxPooling2D(2,2))\n",
    "model1b.add(Dropout(0.3))\n",
    "\n",
    "model1b.add(Flatten())\n",
    "\n",
    "model1b.add(Dense(128, activation='relu'))\n",
    "model1b.add(Dropout(0.25))\n",
    "model1b.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1b.compile(SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set1b = train_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=32,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set1b = test_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=32,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1b=callbacks.ModelCheckpoint('m1bcp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1b= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=4,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1b=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.02, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60/60 [==============================] - 2837s 47s/step - loss: 0.9442 - accuracy: 0.5021 - val_loss: 0.5669 - val_accuracy: 0.7167\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56688, saving model to m1bcp.h5\n",
      "Epoch 2/20\n",
      "60/60 [==============================] - 403s 7s/step - loss: 0.6350 - accuracy: 0.6792 - val_loss: 0.4451 - val_accuracy: 0.7667\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56688 to 0.44506, saving model to m1bcp.h5\n",
      "Epoch 3/20\n",
      "60/60 [==============================] - 398s 7s/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.5822 - val_accuracy: 0.7167\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.44506\n",
      "Epoch 4/20\n",
      "60/60 [==============================] - 383s 6s/step - loss: 0.3917 - accuracy: 0.8193 - val_loss: 0.5184 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.44506\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00019999999552965166.\n",
      "Epoch 5/20\n",
      "60/60 [==============================] - 384s 6s/step - loss: 0.3472 - accuracy: 0.8589 - val_loss: 0.3758 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44506 to 0.37575, saving model to m1bcp.h5\n",
      "Epoch 6/20\n",
      "60/60 [==============================] - 413s 7s/step - loss: 0.2229 - accuracy: 0.9073 - val_loss: 0.2180 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.37575 to 0.21798, saving model to m1bcp.h5\n",
      "Epoch 7/20\n",
      "60/60 [==============================] - 427s 7s/step - loss: 0.1942 - accuracy: 0.9286 - val_loss: 0.3562 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.21798\n",
      "Epoch 8/20\n",
      "60/60 [==============================] - 1003s 17s/step - loss: 0.1829 - accuracy: 0.9255 - val_loss: 0.2729 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21798\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 9/20\n",
      "60/60 [==============================] - 600s 10s/step - loss: 0.1732 - accuracy: 0.9328 - val_loss: 0.3420 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21798\n",
      "Epoch 10/20\n",
      "60/60 [==============================] - 469s 8s/step - loss: 0.1647 - accuracy: 0.9370 - val_loss: 0.1236 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.21798 to 0.12361, saving model to m1bcp.h5\n",
      "Epoch 11/20\n",
      "60/60 [==============================] - 459s 8s/step - loss: 0.1686 - accuracy: 0.9365 - val_loss: 0.2752 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.12361\n",
      "Epoch 12/20\n",
      "60/60 [==============================] - 477s 8s/step - loss: 0.1621 - accuracy: 0.9396 - val_loss: 0.2463 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12361\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-08.\n",
      "Epoch 13/20\n",
      "60/60 [==============================] - 477s 8s/step - loss: 0.1657 - accuracy: 0.9385 - val_loss: 0.3677 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.12361\n",
      "Epoch 14/20\n",
      "60/60 [==============================] - 480s 8s/step - loss: 0.1610 - accuracy: 0.9385 - val_loss: 0.2856 - val_accuracy: 0.9000\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.12361\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5999999902760465e-09.\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1b=model1b.fit_generator(train_set1b,\n",
    "                             steps_per_epoch=1920//32,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1b,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1b,cb1b,ro1b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1c=Sequential()\n",
    "model1c.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1c.add(MaxPooling2D(2,2))\n",
    "model1c.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1c.add(MaxPooling2D(2,2))\n",
    "model1c.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1c.add(MaxPooling2D(2,2))\n",
    "model1c.add(Dropout(0.3))\n",
    "\n",
    "model1c.add(Flatten())\n",
    "\n",
    "model1c.add(Dense(128, activation='relu'))\n",
    "model1c.add(Dropout(0.25))\n",
    "model1c.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1c.compile(SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set1c = train_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=64,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set1c = test_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=64,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1c=callbacks.ModelCheckpoint('m1ccp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1c= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=5,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1c=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 666s 22s/step - loss: 0.9349 - accuracy: 0.5245 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.54863, saving model to m1ccp.h5\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1339s 45s/step - loss: 0.5230 - accuracy: 0.7651 - val_loss: 0.4139 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.54863 to 0.41391, saving model to m1ccp.h5\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1422s 47s/step - loss: 0.3946 - accuracy: 0.8286 - val_loss: 0.2995 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.41391 to 0.29948, saving model to m1ccp.h5\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2923s 97s/step - loss: 0.2424 - accuracy: 0.9005 - val_loss: 0.2477 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.29948 to 0.24767, saving model to m1ccp.h5\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1656s 55s/step - loss: 0.1581 - accuracy: 0.9391 - val_loss: 0.3282 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24767\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1010s 34s/step - loss: 0.1322 - accuracy: 0.9490 - val_loss: 0.2455 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.24767 to 0.24552, saving model to m1ccp.h5\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 655s 22s/step - loss: 0.0950 - accuracy: 0.9677 - val_loss: 0.2376 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24552 to 0.23759, saving model to m1ccp.h5\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 652s 22s/step - loss: 0.0864 - accuracy: 0.9656 - val_loss: 0.4211 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23759\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 783s 26s/step - loss: 0.0728 - accuracy: 0.9688 - val_loss: 0.2755 - val_accuracy: 0.8833\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.23759\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999776482583e-05.\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 650s 22s/step - loss: 0.1336 - accuracy: 0.9495 - val_loss: 0.3509 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.23759\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 654s 22s/step - loss: 0.0551 - accuracy: 0.9792 - val_loss: 0.2178 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.23759 to 0.21784, saving model to m1ccp.h5\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 651s 22s/step - loss: 0.0464 - accuracy: 0.9812 - val_loss: 0.2086 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.21784 to 0.20856, saving model to m1ccp.h5\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 660s 22s/step - loss: 0.0455 - accuracy: 0.9818 - val_loss: 0.2151 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20856\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 647s 22s/step - loss: 0.0415 - accuracy: 0.9844 - val_loss: 0.2233 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20856\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 678s 23s/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.2247 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20856\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 952s 32s/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 0.2247 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20856\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-09.\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 660s 22s/step - loss: 0.0409 - accuracy: 0.9839 - val_loss: 0.2246 - val_accuracy: 0.9333\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20856\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1c=model1c.fit_generator(train_set1c,\n",
    "                             steps_per_epoch=1920//64,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1c,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1c,cb1c,ro1c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1d=Sequential()\n",
    "model1d.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1d.add(MaxPooling2D(2,2))\n",
    "model1d.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1d.add(MaxPooling2D(2,2))\n",
    "model1d.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1d.add(MaxPooling2D(2,2))\n",
    "model1d.add(Dropout(0.3))\n",
    "\n",
    "model1d.add(Flatten())\n",
    "\n",
    "model1d.add(Dense(128, activation='relu'))\n",
    "model1d.add(Dropout(0.25))\n",
    "model1d.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1d.compile(SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set1d = train_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set1d = test_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "cb1d=callbacks.ModelCheckpoint('m1dcp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es1d= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=5,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro1d=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 308s 3s/step - loss: 0.8814 - accuracy: 0.5635 - val_loss: 0.5613 - val_accuracy: 0.7170\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56126, saving model to m1dcp.h5\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 276s 2s/step - loss: 0.5104 - accuracy: 0.7802 - val_loss: 0.7254 - val_accuracy: 0.8495\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.56126\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 284s 2s/step - loss: 0.2649 - accuracy: 0.8917 - val_loss: 0.3377 - val_accuracy: 0.8499\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56126 to 0.33771, saving model to m1dcp.h5\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 277s 2s/step - loss: 0.1512 - accuracy: 0.9292 - val_loss: 0.5152 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33771\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 274s 2s/step - loss: 0.1329 - accuracy: 0.9516 - val_loss: 0.3257 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.33771 to 0.32567, saving model to m1dcp.h5\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 1434s 12s/step - loss: 0.0924 - accuracy: 0.9604 - val_loss: 0.0785 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.32567 to 0.07846, saving model to m1dcp.h5\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 279s 2s/step - loss: 0.0856 - accuracy: 0.9646 - val_loss: 0.5038 - val_accuracy: 0.8665\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.07846\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 280s 2s/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 1.2972 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.07846\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999776482583e-05.\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 265s 2s/step - loss: 0.0672 - accuracy: 0.9755 - val_loss: 2.4783e-04 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07846 to 0.00025, saving model to m1dcp.h5\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 276s 2s/step - loss: 0.0434 - accuracy: 0.9828 - val_loss: 0.6761 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00025\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 534s 4s/step - loss: 0.0270 - accuracy: 0.9901 - val_loss: 0.2754 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 315s 3s/step - loss: 0.0307 - accuracy: 0.9885 - val_loss: 0.1816 - val_accuracy: 0.8666\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00025\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 338s 3s/step - loss: 0.0240 - accuracy: 0.9911 - val_loss: 0.5449 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00025\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-09.\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 342s 3s/step - loss: 0.0307 - accuracy: 0.9891 - val_loss: 0.4527 - val_accuracy: 0.8663\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00025\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "++.history1d=model1d.fit_generator(train_set1d,\n",
    "                             steps_per_epoch=1920//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1d,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1d,cb1d,ro1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1e=Sequential()\n",
    "model1e.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model1e.add(MaxPooling2D(2,2))\n",
    "model1e.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model1e.add(MaxPooling2D(2,2))\n",
    "model1e.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model1e.add(MaxPooling2D(2,2))\n",
    "model1e.add(Dropout(0.3))\n",
    "\n",
    "model1e.add(Flatten())\n",
    "\n",
    "model1e.add(Dense(128, activation='relu'))\n",
    "model1e.add(Dropout(0.25))\n",
    "model1e.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model1e.compile(SGD(learning_rate=0.001, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model1e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb1e=callbacks.ModelCheckpoint('m1ecp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 383s 3s/step - loss: 0.9772 - accuracy: 0.5240 - val_loss: 0.7424 - val_accuracy: 0.5338\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74237, saving model to m1ecp.h5\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 294s 2s/step - loss: 0.6391 - accuracy: 0.7354 - val_loss: 0.3301 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.74237 to 0.33009, saving model to m1ecp.h5\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 317s 3s/step - loss: 0.3916 - accuracy: 0.8448 - val_loss: 0.2992 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33009 to 0.29918, saving model to m1ecp.h5\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 416s 3s/step - loss: 0.2625 - accuracy: 0.9031 - val_loss: 0.1996 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.29918 to 0.19956, saving model to m1ecp.h5\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 312s 3s/step - loss: 0.2115 - accuracy: 0.9187 - val_loss: 0.3453 - val_accuracy: 0.8995\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19956\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 300s 2s/step - loss: 0.1590 - accuracy: 0.9375 - val_loss: 0.0038 - val_accuracy: 0.8501\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19956 to 0.00385, saving model to m1ecp.h5\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 299s 2s/step - loss: 0.1288 - accuracy: 0.9469 - val_loss: 0.1740 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00385\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 294s 2s/step - loss: 0.0982 - accuracy: 0.9646 - val_loss: 0.0510 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00385\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 292s 2s/step - loss: 0.0923 - accuracy: 0.9688 - val_loss: 0.3127 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00385\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 291s 2s/step - loss: 0.0791 - accuracy: 0.9740 - val_loss: 0.6063 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00385\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 292s 2s/step - loss: 0.0740 - accuracy: 0.9771 - val_loss: 0.4862 - val_accuracy: 0.9334\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00385\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1e=model1e.fit_generator(train_set1d,\n",
    "                             steps_per_epoch=1920//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set1d,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es1d,cb1e,ro1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Nesterov\n",
    "model2=Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "model2.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "model2.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model2.compile(SGD(learning_rate=0.01, momentum=0.9, nesterov='True'), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1920 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_set2 = train_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/train',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=True)\n",
    "\n",
    "test_set2 = test_datagen.flow_from_directory('E:/assign_4_rdy/Assignment_3/test',\n",
    "                                             target_size=(200,200),\n",
    "                                              batch_size=16,\n",
    "                                             class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb2=callbacks.ModelCheckpoint('m2cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "es2= callbacks.EarlyStopping(monitor='val_loss',\n",
    "                            min_delta=0,\n",
    "                            patience=4,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True)\n",
    "\n",
    "ro2=callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=2, verbose=1, min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 301s 3s/step - loss: 0.8849 - accuracy: 0.5333 - val_loss: 0.4540 - val_accuracy: 0.7841\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45401, saving model to m2cp.h5\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 294s 2s/step - loss: 0.4856 - accuracy: 0.7901 - val_loss: 0.2858 - val_accuracy: 0.8663\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45401 to 0.28576, saving model to m2cp.h5\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 294s 2s/step - loss: 0.2416 - accuracy: 0.8984 - val_loss: 0.6143 - val_accuracy: 0.9163\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28576\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 296s 2s/step - loss: 0.1386 - accuracy: 0.9474 - val_loss: 0.2094 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.28576 to 0.20938, saving model to m2cp.h5\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 295s 2s/step - loss: 0.1001 - accuracy: 0.9641 - val_loss: 0.0331 - val_accuracy: 0.9336\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20938 to 0.03306, saving model to m2cp.h5\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 297s 2s/step - loss: 0.0952 - accuracy: 0.9656 - val_loss: 0.0554 - val_accuracy: 0.9832\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.03306\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 307s 3s/step - loss: 0.0692 - accuracy: 0.9766 - val_loss: 0.5668 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03306\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 9.999999776482583e-05.\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 299s 2s/step - loss: 0.1397 - accuracy: 0.9464 - val_loss: 0.0439 - val_accuracy: 0.9669\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.03306\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 295s 2s/step - loss: 0.0855 - accuracy: 0.9682 - val_loss: 0.0189 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03306 to 0.01893, saving model to m2cp.h5\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 301s 3s/step - loss: 0.0559 - accuracy: 0.9766 - val_loss: 0.0584 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01893\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 301s 3s/step - loss: 0.0604 - accuracy: 0.9812 - val_loss: 0.0100 - val_accuracy: 0.9667\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01893 to 0.01005, saving model to m2cp.h5\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 302s 3s/step - loss: 0.0451 - accuracy: 0.9833 - val_loss: 0.5414 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01005\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 306s 3s/step - loss: 0.0485 - accuracy: 0.9844 - val_loss: 0.1132 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01005\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 305s 3s/step - loss: 0.0489 - accuracy: 0.9828 - val_loss: 0.0386 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01005\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 304s 3s/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 0.0647 - val_accuracy: 0.9502\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01005\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-09.\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2=model2.fit_generator(train_set2,\n",
    "                             steps_per_epoch=1920//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set2,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es2,cb2,ro2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RMSprop\n",
    "model3=Sequential()\n",
    "model3.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model3.add(MaxPooling2D(2,2))\n",
    "model3.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model3.add(MaxPooling2D(2,2))\n",
    "model3.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model3.add(MaxPooling2D(2,2))\n",
    "model3.add(Dropout(0.3))\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model3.compile(RMSprop(), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb3=callbacks.ModelCheckpoint('m3cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 353s 3s/step - loss: 0.9023 - accuracy: 0.6677 - val_loss: 0.5051 - val_accuracy: 0.7998\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50505, saving model to m3cp.h5\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 298s 2s/step - loss: 0.3085 - accuracy: 0.8859 - val_loss: 0.3649 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50505 to 0.36487, saving model to m3cp.h5\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 320s 3s/step - loss: 0.1606 - accuracy: 0.9422 - val_loss: 0.1272 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36487 to 0.12716, saving model to m3cp.h5\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 298s 2s/step - loss: 0.0925 - accuracy: 0.9646 - val_loss: 0.8826 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.12716\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 302s 3s/step - loss: 0.0667 - accuracy: 0.9760 - val_loss: 0.2784 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.12716\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 313s 3s/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 3.1789e-07 - val_accuracy: 0.9165\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12716 to 0.00000, saving model to m3cp.h5\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 316s 3s/step - loss: 0.0184 - accuracy: 0.9922 - val_loss: 2.8089e-06 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00000\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 320s 3s/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.3001 - val_accuracy: 0.9165\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 318s 3s/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.0113 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00000\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 314s 3s/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.9988e-04 - val_accuracy: 0.9162\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "history3=model3.fit_generator(train_set2,\n",
    "                             steps_per_epoch=1920//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set2,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es2,cb3,ro2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "model4=Sequential()\n",
    "model4.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "model4.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "model4.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "model4.add(Dropout(0.3))\n",
    "\n",
    "model4.add(Flatten())\n",
    "\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dropout(0.25))\n",
    "model4.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model4.compile(Adam(), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb4=callbacks.ModelCheckpoint('m4cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 325s 3s/step - loss: 0.6050 - accuracy: 0.7323 - val_loss: 0.3002 - val_accuracy: 0.9003\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30023, saving model to m4cp.h5\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 324s 3s/step - loss: 0.1948 - accuracy: 0.9292 - val_loss: 0.0546 - val_accuracy: 0.9333\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30023 to 0.05463, saving model to m4cp.h5\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 335s 3s/step - loss: 0.1142 - accuracy: 0.9547 - val_loss: 0.5719 - val_accuracy: 0.8334\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.05463\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 353s 3s/step - loss: 0.0885 - accuracy: 0.9667 - val_loss: 0.1917 - val_accuracy: 0.9165\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.05463\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 327s 3s/step - loss: 0.0384 - accuracy: 0.9859 - val_loss: 0.3396 - val_accuracy: 0.8998\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.05463\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 342s 3s/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.4270 - val_accuracy: 0.9002\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05463\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-07.\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "history4=model4.fit_generator(train_set2,\n",
    "                             steps_per_epoch=1920//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set2,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es2,cb4,ro2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 46, 46, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 23, 23, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 67712)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               8667264   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 8,760,899\n",
      "Trainable params: 8,760,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Nadam\n",
    "model5=Sequential()\n",
    "model5.add(Conv2D(32, kernel_size=(3,3),input_shape=(200,200,3), activation='relu'))\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "model5.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "model5.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "model5.add(Dropout(0.3))\n",
    "\n",
    "model5.add(Flatten())\n",
    "\n",
    "model5.add(Dense(128, activation='relu'))\n",
    "model5.add(Dropout(0.25))\n",
    "model5.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model5.compile(Nadam(), metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb5=callbacks.ModelCheckpoint('m5cp.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 359s 3s/step - loss: 0.8126 - accuracy: 0.6734 - val_loss: 0.2430 - val_accuracy: 0.8675\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24299, saving model to m5cp.h5\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 345s 3s/step - loss: 0.2136 - accuracy: 0.9104 - val_loss: 0.3750 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24299\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 338s 3s/step - loss: 0.1138 - accuracy: 0.9547 - val_loss: 0.2268 - val_accuracy: 0.8830\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24299 to 0.22679, saving model to m5cp.h5\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 608s 5s/step - loss: 0.0531 - accuracy: 0.9786 - val_loss: 0.3007 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22679\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 614s 5s/step - loss: 0.1040 - accuracy: 0.9661 - val_loss: 0.3002 - val_accuracy: 0.8830\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22679\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 333s 3s/step - loss: 0.0335 - accuracy: 0.9875 - val_loss: 0.4144 - val_accuracy: 0.8837\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.22679\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 315s 3s/step - loss: 0.0336 - accuracy: 0.9885 - val_loss: 0.0194 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.22679 to 0.01940, saving model to m5cp.h5\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 314s 3s/step - loss: 0.0226 - accuracy: 0.9948 - val_loss: 0.1913 - val_accuracy: 0.8994\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01940\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 311s 3s/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.8271 - val_accuracy: 0.9001\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01940\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-07.\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 329s 3s/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.1836 - val_accuracy: 0.8999\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01940\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 339s 3s/step - loss: 0.0197 - accuracy: 0.9969 - val_loss: 0.3198 - val_accuracy: 0.9001\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01940\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-09.\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "history5=model5.fit_generator(train_set2,\n",
    "                             steps_per_epoch=1920//16,\n",
    "                             epochs=20,\n",
    "                             validation_data=test_set2,\n",
    "                             validation_steps=250,\n",
    "                             callbacks=[es2,cb5,ro2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and Predicting the model\n",
    "# We'll load two models (having minimum loss):\n",
    "# model1d (SGD) and  model4 (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a = load_model('m1dcp.h5')\n",
    "model_b = load_model('m4cp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model,img_string):\n",
    "    image=cv2.imread(img_string)\n",
    "    image=cv2.resize(image,(200,200),interpolation=cv2.INTER_AREA)\n",
    "    image=image.reshape(1,200,200,3)\n",
    "    res=model.predict_classes(image, 1, verbose=0)[0]\n",
    "    if res==0:\n",
    "        pred='Saree'\n",
    "    if res==1:\n",
    "        pred='Shirt'\n",
    "    if res==2:\n",
    "        pred='Tshirt'\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\dell\\anaconda3\\envs\\tensorflow\\lib\\site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\dell\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from opencv-python) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "prediction(model_a, 'saree.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(model_a, 'shirt.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(model_a, 'tshirt.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
